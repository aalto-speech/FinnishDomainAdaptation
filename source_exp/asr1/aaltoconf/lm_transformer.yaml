# network architecture
model-module: transformer
att-unit: 256
embed-unit: 128
head: 4
layer: 12
pos-enc: none
unit: 2048

# minibatch related
batchsize: 32
maxlen: 150

# optimization related
opt: adam
schedulers: lr=cosine
dropout-rate: 0.05
epoch: 50
gradclip: 1.0
lr: 1e-4
lr-cosine-total: 100000
lr-cosine-warmup: 1000
patience: 3
sortagrad: 0